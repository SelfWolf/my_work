# 学习记录

1. 岛屿计数问题，DFS、BFS、迷宫的最短路径、DFS和BFS适用场景、DFS非递归遍历
   1. BFS(广度优先搜索)
      1. 选择一个节点作为起始节点，染成灰色，其余节点为白色
      2. 将起始节点放入队列
      3. 从队列首部选择一个节点，并找出所有邻接节点，并将邻接节点放入队列尾部
      4. 已访问过的是黑色，未访问过的是白色，在队列的是灰色
      5. 同样方法处理下一个节点
   2. DFS(深度优先搜索)
      1. 选择一个节点作为起始节点
      2. 将起始节点假如队列
      3. 从队列首部选择一个节点，找到一个未访问的邻接节点并访问
      4. 重复步骤3知道无邻接节点，然后返回
   3. DFS和BFS区别
      1. BFS用来搜索最短路径；DFS用来搜索全部路径
      2. DFS空间效率高，BFS需要记录中间过程
   4. 例题：黄金矿工&封闭岛屿
2. CNN反向传播，怎么过全连接、池化层、卷积层
   1. 池化层：最大池化只需要反向对应位置即可，其他位置为0；平均池化为误差除以区域值
   2. 卷积层：原图的误差，等于卷积结果误差经过零填充后，与卷积核旋转180度后的卷积
3. 过拟合的方法
   1. 早停
   2. dropout
   3. 正则化
   4. 数据增强
4. SGD为什么可以online learning、Adam原理
   1. SGD通过牺牲一定的精度，采用单样本计算损失，达到快速更新参数的目的，在运行速度、计算方式上符合online learning的要求
   2. 自适应学习率+动量
5. 二叉树宽度、深度
   1. 二叉树宽度用队列层次遍历，保存每层的宽度
   2. 二叉树深度用递归
6. 小兔的棋盘
   1. 类似斐波那契数列，往前走到一个点，只能从上方或者左方到达因此dp[i,j]=dp[i-1,j]+dp[i,j-1],dp[i,i]=dp[i,j-1]
   2. 不越过对角线，棋盘的对称性考虑，可以直接结果乘以2，得到最终的数值
7. leetcode76、leetcode856、链表重复节点删除、leetcode72、leetcode222、leetcode448、leetcode102、42、124
8. 五局三胜和三局两胜的公平性
    1. 在水平相当，即胜率为0.5的情况下，是公平的
    2. 如果胜率大于0.5，那么局数越多越有利
9. A文件有m个专有名词，B文件有n个query，统计专有名词出现次数
   1. 类似给定歌手以及用户输入，统计歌手频次的问题
   2. 解决方法：专有名词长度排序，按照名词长度做滑动窗口去匹配query，分布式统计
10. 从访问日志中，找访问次数最多的TopK用户
    1. 先统计，再排序最小堆排序
    2. 通过hash划分为k个文件，每个文件的最多类就是
11. xgboost模型、GBDT原理，如何多分类
12. 梯度消失、梯度爆炸
    1. 预训练+微调
    2. 正则：L1和L2正则
    3. 残差连接：相当于恒等映射
    4. BN：通过一定规范化手段将每层NN的激活输入值分布拉回到标准正态分布，使得激活值落在非线性函数比较敏感的区域，产生较大的梯度，梯度变大意味着收敛速度快，能加快训练速度
13. KL散度和交叉熵关系
    1. 保证真实数据分布不变的情况下，最小化KL散度等价于最小化交叉熵
    2. KL(A||B)=-S(A)+H(A, B)，A代表真实数据分布，因此保持不变
14. 现有模型需要多少额外标注数据？
    1. 取决于执行的任务、最终可接受的性能、现有的特征、数据噪声情况以及模型复杂度等
15. 几何分布的期望
    1. 定义：在伯努利实验中，时间第k次发生的概率，记做几何分布
    2. 期望等于发生概率p的倒数；方差等于1-p/p^2
16. 分类问题的指标、ROC、MAP、AUC、特征选择的方法
17. MCMC采样、马尔科夫链、CRF、FM是否可以特征选择？
18. 排序算法分析、堆排序、快排
19. 排序数组中，绝对值不同的个数
20. 概率：不均匀硬币抛五次，两正三反，下一次正的概率；抛五十次，二十次正三十次反，下一次正的概率
21. 1-N中字符1出现的次数
22. a+b>c？考虑溢出
23. attention的实现、BN原理和作用
24. 特征工程、PCA原理
25. 给M个正样本、N个负样本，以及预测值P，计算AUC，如果预测值都乘以1.2，AUC如何变化
26. softmax推导、交叉熵推导
27. k个有序链表的合并
28. path_sum 变形
29. 数据不均衡处理方法
30. 抖音红人的总数、下一个全排列
31. 单链表找公共节点
32. 0-1矩阵，找1的最大连通域，计算其面积
33. xgboost和GBDT的分裂方式、L1和L2的区别、xgb如何处理类别特征的
34. 编辑距离、对称二叉树、平衡二叉树判断、海量TopK问题、二叉树层次遍历、链表翻转、正则表达式匹配
35. bert的改进，定制化bert，bert原理
    1. Bert基于预训练+微调的模型，使用Mask+next sentence的方式在超大规模语料上进行预训练
    2. 算力和推理速度制约了Bert在实际生产环境的应用
    3. 模型压缩+词mask训练+XLNet
36. 如何标注数据（active learning）
    1. 主动学习：基于选择策略，选择未标注数据进行标注，然后喂给模型进行训练，直到满足终止条件
    2. 选择策略的确定是主观的，不具泛化能力；情感分析中是人工标注分类模型推理错误的样本
    3. 在保证质量的前提下增加数量，防止过度拟合噪声
    4. 主动学习区别于半监督学习的点在于人工参与
37. 已知方差，求方差和
38. LR、SVM、softmax、L1、L2、Bert、Transformer、GBDT、Xgb